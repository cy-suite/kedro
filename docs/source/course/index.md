# Learn Kedro with hands-on video

If you prefer to learn by following a video tutorial, you can follow our hands-on video course "Introduction to Kedro: Building Maintainable Data Pipelines" on YouTube.

The course is structured into sections, which are further divided in short videos covering a specific Kedro topics. You'll walk through the [spaceflights tutorial](../tutorial/spaceflights_tutorial.md) to get hands-on with that example and pick up key Kedro concepts like datasets and the Kedro Data Catalog, nodes and pipelines, and configuration management.

## Who is this course for?

This course is for data scientists, data engineers and machine learning engineers. You can be junior, mid-level or senior in your field of work. You're likely to be hands-on with projects, or a decision-maker who regularly makes design and implementation choices about Python data products.

We assume you know these concepts:

* Python basics (coding on Jupyter and other notebook interfaces)
* Manipulating data with pandas
* Visualising insights
* Command line basics

We don't assume knowledge of software engineering in Python, so the course contains information about reusability principles, how to create a Python package, and how to use version control.

## What you'll learn

In short, you'll learn answers to the following:

* What is Kedro? How does it help you create maintainable, reusable data science code?
* How does Kedro fit into the data science ecosystem?
* What do you need to do to create a Kedro project?
* How can you refactor a Jupyter notebook to a Kedro project?
* How do you package Python code as a library?
* How do you work with Kedro projects in VSCode?
* What are namespaces and dataset factories?
* What is needed to deploy a Kedro project using container solutions like Docker and open source orchestrators like Airflow?
* What are Kedro plugins?
* How can you contribute to Kedro?


## Index of videos 

"Introduction to Kedro: Building Maintainable Data Pipelines" is split into the following videos:

- Part 0: Introduction
    - 0.1. Data science in production: the good, the bad, and the ugly
    - 0.2. What is Kedro?
    - 0.3. Kedro and data orchestrators
    - 0.4. Where does Kedro fit in the data science ecosystem?
- Part 1: Get started with Kedro
    - 1.1. The spaceflights starter
    - 1.2. Create a Kedro project from scratch
    - 1.3. Use Kedro from Jupyter notebook
    - 1.4. Set up the Kedro Data Catalog
    - 1.5. Explore the spaceflights data
    - 1.6. Refactor your data processing code into functions
    - 1.7. Create your first data pipeline with Kedro
    - 1.8. Assemble your nodes into a Kedro pipeline
    - 1.9. Run your Kedro pipeline
    - 1.10. Visualise your data pipeline with Kedro-Viz
- Part 2: Make complex Kedro pipelines
    - 2.1. Merge different dataframes in Kedro
    - 2.2. Predict prices using machine learning
    - 2.3. Refactor your data science code into functions
    - 2.4. How to work with parameters in Kedro
    - 2.5. Create a Kedro pipeline with parameters
    - 2.6. Reuse your Kedro pipeline using namespaces
    - 2.7. Kedro pipeline runners
    - 2.8. Create Kedro datasets dynamically using factories
- Part 3: Ship your Kedro project to production
    - 3.1. Define your own Kedro environments
    - 3.2. Use S3 and MinIO cloud storage with Kedro
    - 3.3. Package your Kedro project into a Python wheel
    - 3.4. Turn your Kedro project into a Docker container
    - 3.5. Deploy your Kedro project to Apache Airflow
- Part 4: Continue your Kedro journey

You don't need to register for the course and you can skip around the sections to find help on a particular area as you pick up the skills needed to build your own Kedro projects.
