import copy
from io import BytesIO
from pathlib import PurePosixPath
from typing import Any, Dict, List, Optional

import gcsfs
import pandas as pd

from kedro.io.core import AbstractVersionedDataSet, DataSetError, Version


class JsonGCSDataSet(AbstractVersionedDataSet):
    """``JsonGCSDataSet`` loads and saves data to a file in gcs. It uses google-cloud-storage
    to read and write from S3 and pandas to handle the csv file.

    Example:
    ::

        >>> from kedro.contrib.io.gcs.json_gcs import JsonGCSDataSet
        >>> import pandas as pd
        >>>
        >>> data = pd.DataFrame({'col1': [1, 2], 'col2': [4, 5],
        >>>                      'col3': [5, 6]})
        >>>
        >>> data_set = JsonGCSDataSet(filepath="test.csv",
        >>>                          bucket_name="test_bucket",
        >>>                          load_args=None,
        >>>                          save_args={"index": False})
        >>> data_set.save(data)
        >>> reloaded = data_set.load()
        >>>
        >>> assert data.equals(reloaded)
    """

    DEFAULT_LOAD_ARGS = {}  # type: Dict[str, Any]
    DEFAULT_SAVE_ARGS = {"index": False}  # type: Dict[str, Any]

    # pylint: disable=too-many-arguments
    def __init__(
        self,
        filepath: str,
        bucket_name: str,
        credentials: Optional[Dict[str, Any]] = None,
        project: Optional[str] = None,
        load_args: Optional[Dict[str, Any]] = None,
        save_args: Optional[Dict[str, Any]] = None,
        version: Version = None,
    ) -> None:
        """Creates a new instance of ``CSVGCSDataSet`` pointing to a concrete
        csv file on gcs.

        Args:
            filepath: Path to a json file.
            bucket_name: gcs bucket name.
            credentials: Credentials to access the gcs bucket. It must be a google.auth.credentials.Credentials object
                (see https://google-auth.readthedocs.io/en/latest/user-guide.html#service-account-private-key-files).
            project: The GCP project. If not specified, then the default is inferred by a remote request
            load_args: Pandas options for loading csv files.
                Here you can find all available arguments:
                https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
                All defaults are preserved.
            save_args: Pandas options for saving csv files.
                Here you can find all available arguments:
                https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html
                All defaults are preserved, but "index", which is set to False.
            version: If specified, should be an instance of
                ``kedro.io.core.Version``. If its ``load`` attribute is
                None, the latest version will be loaded. If its ``save``
                attribute is None, save version will be autogenerated.

        """
        _gcs = gcsfs.GCSFileSystem(credentials=credentials, project=project)
        super().__init__(
            PurePosixPath("{}/{}".format(bucket_name, filepath)),
            version,
            exists_function=_gcs.exists,
            glob_function=_gcs.glob,
        )
        self._bucket_name = bucket_name

        # Handle default load and save arguments
        self._load_args = copy.deepcopy(self.DEFAULT_LOAD_ARGS)
        if load_args is not None:
            self._load_args.update(load_args)
        self._save_args = copy.deepcopy(self.DEFAULT_SAVE_ARGS)
        if save_args is not None:
            self._save_args.update(save_args)

        self._gcs = _gcs

    def _describe(self) -> Dict[str, Any]:
        return dict(
            filepath=self._filepath,
            bucket_name=self._bucket_name,
            load_args=self._load_args,
            save_args=self._save_args,
            version=self._version,
        )

    def _load(self) -> pd.DataFrame:
        load_path = PurePosixPath(self._get_load_path())

        with self._gcs.open(str(load_path), mode="rb") as gcs_file:
            return pd.read_json(gcs_file, **self._load_args)

    def _save(self, data: pd.DataFrame) -> None:
        save_path = PurePosixPath(self._get_save_path())

        with self._gcs.open(str(save_path), mode="wb") as gcs_file:
            gcs_file.write(data.to_json(**self._save_args).encode("utf8"))

        load_path = PurePosixPath(self._get_load_path())
        self._check_paths_consistency(load_path, save_path)

    def _exists(self) -> bool:
        try:
            load_path = self._get_load_path()
        except DataSetError:
            return False

        return self._gcs.exists(load_path)
